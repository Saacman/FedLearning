{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from fedlern.models.mlp import MLP\n",
    "from fedlern.models.resnet_v2 import ResNet18\n",
    "from fedlern.train_utils import *\n",
    "from fedlern.quant_utils import *\n",
    "import fedlern.utils as utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cuda_device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu:0\")\n",
    "\n",
    "#stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "stats = (0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784)\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = prepare_dataloader_cifar(num_workers=8, train_batch_size=batch_size ,eval_batch_size=batch_size, stats=stats)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET no quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 92.49999237060547%\n",
      "44.77 MB\n",
      "FP32 CPU Inference Latency: 11.95 ms / sample\n",
      "FP32 CUDA Inference Latency: 5.32 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "model = ResNet18()\n",
    "load_model(model, '../saved_models/resnet18_cifar10_92-5.pt', device)\n",
    "\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "\n",
    "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 92.24999237060547%\n",
      "44.77 MB\n",
      "FP32 CPU Inference Latency: 7.22 ms / sample\n",
      "FP32 CUDA Inference Latency: 5.40 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, '../saved_models/resnet18_cifar10_92-2.pt', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 81.02999877929688%\n",
      "44.77 MB\n",
      "CPU Inference Latency: 9.04 ms / sample\n",
      "CUDA Inference Latency: 2.93 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, '../saved_models/resnet_fedlern_dyn851bits_2023-08-25_15-32.pth', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET Quantization 4 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 83.5199966430664%\n",
      "44.77 MB\n",
      "CPU Inference Latency: 7.00 ms / sample\n",
      "CUDA Inference Latency: 5.32 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, '../saved_models/resnet_4bits_2023-06-29_22-17.pth', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"CPU Inference Latency: {:.2f} ms / sample\".format(cpu_inference_latency * 1000))\n",
    "print(\"CUDA Inference Latency: {:.2f} ms / sample\".format(gpu_inference_latency * 1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 81.16999816894531%\n",
      "44.77 MB\n",
      "CPU Inference Latency: 7.01 ms / sample\n",
      "CUDA Inference Latency: 4.90 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, '../saved_models/resnet_8bits_2023-06-30_05-04.pth', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"CPU Inference Latency: {:.2f} ms / sample\".format(cpu_inference_latency * 1000))\n",
    "print(\"CUDA Inference Latency: {:.2f} ms / sample\".format(gpu_inference_latency * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 83.0199966430664%\n",
      "44.77 MB\n",
      "CPU Inference Latency: 6.21 ms / sample\n",
      "CUDA Inference Latency: 5.09 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, '../saved_models/resnet_8bits_2023-06-30_00-45.pth', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"CPU Inference Latency: {:.2f} ms / sample\".format(cpu_inference_latency * 1000))\n",
    "print(\"CUDA Inference Latency: {:.2f} ms / sample\".format(gpu_inference_latency * 1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization 16 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 84.44000244140625%\n",
      "44.77 MB\n",
      "CPU Inference Latency: 9.97 ms / sample\n",
      "CUDA Inference Latency: 2.93 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, '../saved_models/resnet_fedlern_16bits_2023-07-26_21-20.pth', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"CPU Inference Latency: {:.2f} ms / sample\".format(cpu_inference_latency * 1000))\n",
    "print(\"CUDA Inference Latency: {:.2f} ms / sample\".format(gpu_inference_latency * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Label:  cat\n",
      "Predicted Label:  cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPJklEQVR4nO3cbazW9XkH8P/Bw83hcEBAwSJQQVQEFNTW0qbaTmcXu2rSpmu7pcvWzL1pXLN1S7tsSV/tIcvSZMmSPTRdky7dusw08yGtOnVtFrsYXIxaxYciilJQQESeDofTwzl7YfKNmSb7XbobbvTzef3lyu/87/uc7//3gmtoZmZmpgOArutmneoDADA4lAIAoRQACKUAQCgFAEIpABBKAYBQCgDEcGtwaGion+coWtqcnD06Upo83GvP9nqFcNd1veEzSvmKI0cOl/LHDu0ppE/UDgMMpJb/q+ymAEAoBQBCKQAQSgGAUAoAhFIAIJQCAKEUAAilAEAoBQBCKQAQzbuP+mtuKT17tP3YlV1GXdd1I4V9RiNzZpdmDxdmT01OlWZPTdXy9hkBb8ZNAYBQCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgDEQKy5GJo1Xcr3Rtrzw8XaGxluX10xNjJamj013X7uqRO1ZzI9MVnKA7wZNwUAQikAEEoBgFAKAIRSACCUAgChFAAIpQBAKAUAQikAEEoBgBiI3Ucz08dL+YlX9jVnp7teafZUb6I5u27NmtLsF1/a05zdsXtXafZMd7iUHxRzu4Wl/Gc++anm7D/fdmtp9onu1VIe3oncFAAIpQBAKAUAQikAEEoBgFAKAIRSACCUAgChFAAIpQBADMSai6oT3YlC+lhp9tHJ9vye3S+WZm+6dH1z9pltT5dm/7ybKeUHxc2//Rul/Jo1FzRntzz0SGn20zsfLuXhnchNAYBQCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAgTsvdR4Ni6/aHSvmXdu1pzk4P0C6jJcPzSvnPfPZXmrObP3BFafbuwjN8df+B0mzATQGA11EKAIRSACCUAgChFAAIpQBAKAUAQikAEEoBgFAKAIQ1FyfR/omfNWfnL91Qmv25z7evlui6rtu0+rzm7LlnLyrNHhkuvGtMTpZmHz1yqDm7Z3xHaTbgpgDA6ygFAEIpABBKAYBQCgCEUgAglAIAoRQACKUAQCgFAEIpABB2H51Ey9Zd1Zz94pe/VJp9zXXXlPJrly5pzvYmp0uzn3v6iebsU48+XJr9yv4DpTxQ46YAQCgFAEIpABBKAYBQCgCEUgAglAIAoRQACKUAQCgFAMKai7dh/uK1pfynP3ljc/bStReWZi8cGS3le4VPfsFI7d1hw6Xrm7MT4wdLs3e/uKuQPqM0u+tOFPPwzuOmAEAoBQBCKQAQSgGAUAoAhFIAIJQCAKEUAAilAEAoBQBCKQAQdh+9wbzm5Irly2qjp6aao732aNd1XTe+v7ZD6Ln9e5qz69asKs2eM6/9XWPD+y4rzV65ZnVz9t4HHinNvvuefy3leSdZUEovW7q8Ofvi3ierhzml3BQACKUAQCgFAEIpABBKAYBQCgCEUgAglAIAoRQACKUAQCgFAGJoZmZmpik4NNTvs/TJGcV8ZR3UdGnyyvOuaM5+95++XZq9e9eLpfxdd/5bc/amm369NPuqj2wu5fvlxw8+Xsr/8sc/W8qPjx9rzp6Y2FGazcm1ZOWHSvmpY+PN2QMvP1o9Tt+0/Ll3UwAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAglAIAUdnpcJo6UYv3zmrPTu4tjd75/JPN2eWLC+foum7vc7tK+f9+YEtz9hM3XFOaPSiu+sAlpfxtP7illP+X77bn/+FvvlWa3U3vruV5W1acf1Epf+jV/c3ZQVpz0cJNAYBQCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAg3gW7j4qmpgrhpaXRa1e371dZsWxJaXZv08ZS/qtfubk5+7HrP1qafbq69oO1XUlHxo82Zx948OHS7K1b7D46mebOn1/KT0xM9Okkp56bAgChFAAIpQBAKAUAQikAEEoBgFAKAIRSACCUAgChFAAIay7+t+n21QVdd7w0et26jzdnZ4+VRnfLN9bWYnxu3eebs3Nm+5q8mQ9fvbk5+4vX1VaFbN1yVyF9ojSbNzr37AW1fzBxuBCurdDousrs/39uCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAglAIAYanNG0z2bfLOXc83Z595bkdp9gUXrSrl7TN6+86a3Z796C98uDT7W99c35w9uvex0mze6MjLe0r5A3teLKSna4c5xdwUAAilAEAoBQBCKQAQSgGAUAoAhFIAIJQCAKEUAAilAEDYdfAGM32b/Oz2Hc3Znzz6eGl2dc0FJ9f6DReX8hetvaA5+7A1F2/b3d//QfFfHCxkjxVnn1puCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAglAIAYffRSXTgyK7m7L33/Kg0e+FZi0r5c9de1JxdvXxJafacUnpwPL5zXym/ckX7c1m9rPb5vO/9lzVnH77/1tJs3sxLp/oAA8NNAYBQCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAg7D46qX7enHxm2/bS5LvuvLeU37D/YHN20Q3Xl2afM3cw3jXan/Zrfvd3/rCUX7/h4ubsn/7ZV0uzN226pJAeKs3uuplinneTwfjtBWAgKAUAQikAEEoBgFAKAIRSACCUAgChFAAIpQBAKAUAwpqLAbX/lQOl/Pj4sVJ+4ZlnlvKno1vvvr+U/+EdtxTz85uz11x7dWn2xesuas5euvnG0uzHttxRyvPu4qYAQCgFAEIpABBKAYBQCgCEUgAglAIAoRQACKUAQCgFAEIpABB2Hw2o2cO1j2bp0iWl/MjoSHN21qzBeXc4Wsh+4+/+sY/Ta/lvfuPbpcl/9dd/0Zz946/9fmn21/+kPfuQPUnvOoPz2w7AKacUAAilAEAoBQBCKQAQSgGAUAoAhFIAIJQCAKEUAAhrLgbU8SPHSvlFI3NL+dHe7ObsyJzS6L66/e4HmrM/vOPWPp6k5u7vfaeU/8offKk5+4nrP1qave3JnzZnrbl493FTACCUAgChFAAIpQBAKAUAQikAEEoBgFAKAIRSACCUAgChFAAIu48G1NTR8VJ+ZFbtoxwpvA7MmimN7rqhYr7g9jvuLaRf6ds56mq7rLb8eEtz9toPXlKavemKje3h0fNLs7vxZ2t5Bo6bAgChFAAIpQBAKAUAQikAEEoBgFAKAIRSACCUAgChFAAIay4G1JGJyVJ+/6HDtfmHDjZnX967rzR73jlLmrPtp3jNtm3PFP/F6Wlqaqpvsy9Ye0Fz9rpfuqY0+77brLk43bkpABBKAYBQCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCE3UcD6pUjR0v5Z3fuKuWX7dzZnD1y7Hhp9vGN69vPsfLc0uwrL7+kOfvwfaXRfTa7lL76Ix/q0zm6bsniRc3Zq66uneO+7/97e3jqUGl211XzvBVuCgCEUgAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAgrLkYUIcnXyjld7/0fCn//Lb2VQdPbn2iNLs7Y7o5urq45uKm3/rV5uzPnttemn3n924p5eeMLmnO/u3ff700e/PmjaV8xdjc9nfBy99/WWn27/3Rl5uzvV5t9cdffu3PS/mue6mYp+vcFAB4HaUAQCgFAEIpABBKAYBQCgCEUgAglAIAoRQACKUAQCgFAOIdv/vojGL+RF9O0X87tz9eyq9fu7I5+9K+A6XZP328fVfSqlWrSrMXzB1rzt78xS+UZt94/cdK+QsuXNOc3bTpktLs8fGp5uxkr/ZrPDanPbv5ystLs89e3L5T64mtT5Vmn3nuslL+4G67j94KNwUAQikAEEoBgFAKAIRSACCUAgChFAAIpQBAKAUAQikAEEoBgOjb7qPqzqGK6UK2+gO2b9bpupHi7IlC9mBx9o7t20r5F567sDk7Ota+z6brum7/3n3N2Qf/a0tp9nvOe29zdmx0YWn2xuJ+osVntT+Xg4cOlWbPntX+vjY6VvnWdt14b3ZzttervTcumD+vOTsyUljC1HXd0iVnlfIHd5fiJcvP29yc/c0v/Fpp9u233dmc3frof5Zmt3BTACCUAgChFAAIpQBAKAUAQikAEEoBgFAKAIRSACCUAgDRtzUXJwrZ9v90/5rRYr5iqpCtrNvouq47u5BdUJw9Wcw/cM9/NGcXn7OsNHv5iuebs88+9nhp9nvXrGrOrj7/4tLs9yxfWcq//HyvOTs5WVly0nVjY/Obs+eurH0+w6OFtRjFfTWv7NvfnJ06crg0+8pN60v5JaPtfyk2Xlqb/alP39CcXbDwzNLs6YljzdkLl9dWf7RwUwAglAIAoRQACKUAQCgFAEIpABBKAYBQCgCEUgAglAIAoRQAiKGZmZmZluCsoaG+HaLpAG9R+waZ1/SzJUf6lH0r+crepuqOp0q+unxrbGRuc3b+4tpOoLOXryrlp6fbf9KJieO1s5zdvtNmxXkrSrN7ixY3Z89cvKg0e3i4/RPdt3dfafb4sdr+qMWL2ncOrb1wTWn22IL2vyw/uu/+0uxHHm3fB/bk1p+UZr9weNf/mXFTACCUAgChFAAIpQBAKAUAQikAEEoBgFAKAIRSACCUAgDRvOZiqLjmopKurjqorl2oqKyL6BVnV37Ofj+TytmrKzSqZ6+YKmQni7Orz7BylurbV6/wG9SrfkKj85qjYwsWlEbPm9e+hmTiaG31x/GpyhPvujm99m/igjNrC3EmJ9u/XVu3P1Wavb87UcpXtPy5d1MAIJQCAKEUAAilAEAoBQBCKQAQSgGAUAoAhFIAIJQCAKEUAIjm3UfDxd1Hle0ds0uT+7tDqNKStU0sXTdayFb3DfV7z09F5ezVn7Ofqp9nNV/Rz/1Rle9K9XvSz+9V9XlXztLPvVfVc1c+n6Y/3q/P230EQIVSACCUAgChFAAIpQBAKAUAQikAEEoBgFAKAIRSACCa11wMFddc1NL9s7CYr6yiOFKcPdGnc3Rdvd0raxT6uV6gn+scqs+wepbxPs6uPMPqipOK6veqcpbqufu5sqafb8f9XEFT+Q52XddNW3MBQIVSACCUAgChFAAIpQBAKAUAQikAEEoBgFAKAIRSACCUAgDRvE6kcUUSAKcxNwUAQikAEEoBgFAKAIRSACCUAgChFAAIpQBAKAUA4n8A4RJVRmFkyOEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load CIFAR-10 dataset and extract an element\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(*stats)])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Pass the data through the model to get predictions\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images.to(device))\n",
    "        s, predicted = torch.max(outputs, 1)\n",
    "        break  # Stop after processing one example\n",
    "\n",
    "# Step 5: Compare the correct label with the predicted label\n",
    "predicted_class = predicted.item()\n",
    "correct_class = labels.item()\n",
    "\n",
    "# Step 6: Print the results\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(\"Correct Label: \", class_names[correct_class])\n",
    "print(\"Predicted Label: \", class_names[predicted_class])\n",
    "\n",
    "# Step 7: Plot the image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize the image\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the test image\n",
    "imshow(images[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
