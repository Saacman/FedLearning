{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.models import ResNet, MLP\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import src.utils as utils\n",
    "%matplotlib inline\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "# Normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform_test)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetB(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetB, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20():\n",
    "    return ResNetB(BasicBlock, [3, 3, 3])\n",
    "\n",
    "def get_model2(model, learning_rate=1e-3, weight_decay=1e-4):\n",
    "\n",
    "    # set the first layer not trainable\n",
    "    # model.features.conv0.weight.requires_grad = False\n",
    "\n",
    "    # all fc layers\n",
    "    weights = [\n",
    "        p for n, p in model.named_parameters()\n",
    "        if 'weight' in n and 'conv' not in n\n",
    "    ]\n",
    "\n",
    "    # all conv layers\n",
    "    weights_to_be_quantized = [\n",
    "        p for n, p in model.named_parameters()\n",
    "        # if 'conv' in n and 'conv0' not in n\n",
    "        if 'conv' in n and 'weight' in n\n",
    "    ]\n",
    "\n",
    "    biases = [\n",
    "        p for n, p in model.named_parameters()\n",
    "        if 'bias' in n\n",
    "    ]    \n",
    "\n",
    "    params = [\n",
    "        {'params': weights, 'weight_decay': weight_decay},\n",
    "        {'params': weights_to_be_quantized, 'weight_decay': weight_decay},\n",
    "        {'params': biases,  'weight_decay': weight_decay}\n",
    "    ]\n",
    "    optimizer = optim.SGD(params, lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss().cuda()\n",
    "    model = model.cuda()  # move the model to gpu\n",
    "    return model, loss, optimizer\n",
    "def quantize_bw(kernel : torch.Tensor):\n",
    "    \"\"\"\n",
    "    binary quantization\n",
    "    Return quantized weights of a layer.\n",
    "    \"\"\"\n",
    "    delta = kernel.abs().mean()\n",
    "    sign = kernel.sign().float()\n",
    "\n",
    "\n",
    "\n",
    "    return sign*delta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET no quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 88.25999450683594%\n",
      "0.81 MB\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model_dict = torch.load('./models/resnet.ckpt')\n",
    "model = ResNet(in_channels=16, num_classes=10)\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "loss, acc = utils.evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "utils.print_model_size(model)\n",
    "#print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET Quantization 4 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "# Normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "# CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform_test)\n",
    "\n",
    "batch_size_test = int(len(test_dataset)/40 )#100\n",
    "batch_size_train = 100\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size_test, shuffle=False)\n",
    "#--------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 68.44999694824219%\n",
      "1.12 MB\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "load_dict = torch.load('./models/resnet_4bits.pth')\n",
    "#print(load_dict.keys())\n",
    "state_dict = load_dict['state']\n",
    "#print(state_dict.keys())\n",
    "model = resnet20()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "loss, acc = utils.evaluate_model(model, test_loader, device)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "utils.print_model_size(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 53.21999740600586%\n",
      "1.12 MB\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "load_dict = torch.load('./models/resnet_2bits.pth')\n",
    "#print(load_dict.keys())\n",
    "state_dict = load_dict['state']\n",
    "#print(state_dict.keys())\n",
    "model = resnet20()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "loss, acc = utils.evaluate_model(model, test_loader, device)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "utils.print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d946fc8105b7421ca4b943ced32a7b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i2=0\n",
      "i2=1\n",
      "i2=2\n",
      "i2=3\n",
      "i2=4\n",
      "i2=5\n",
      "i2=6\n",
      "i2=7\n",
      "i2=8\n",
      "i2=9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9311627379494eac990e39104a04604a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i3=0\n",
      "i3=1\n",
      "i3=2\n",
      "i3=3\n",
      "i3=4\n",
      "i3=5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i3 \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m), leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     16\u001b[0m     \u001b[39m# do something, e.g. sleep\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     bar\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mi3=\u001b[39m\u001b[39m{\u001b[39;00mi3\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.5\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "# from tqdm.auto import tqdm  # notebook compatible\n",
    "import time\n",
    "bar = tqdm(range(5))\n",
    "bar.refresh()\n",
    "for i1 in bar:\n",
    "    \n",
    "    bar.set_description(f\"Training {i1}\",refresh=True)\n",
    "    for i2 in tqdm(range(10), leave=False):\n",
    "        # do something, e.g. sleep\n",
    "        bar.write(f\"i2={i2}\")\n",
    "        time.sleep(0.5)\n",
    "    bar.set_description(f\"Testing {i1}\",refresh=True)\n",
    "    for i3 in tqdm(range(10), leave=False):\n",
    "        # do something, e.g. sleep\n",
    "        bar.write(f\"i3={i3}\")\n",
    "        time.sleep(0.5)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [ 28 * 28, # input\n",
    "                512, 256, 128, 64,\n",
    "                10 ] #output\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # normalize the image with mean=0.5 and std=0.5\n",
    "])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_dataset = datasets.MNIST(root='data/', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['linears.0.scale', 'linears.0.zero_point', 'linears.0._packed_params.dtype', 'linears.0._packed_params._packed_params', 'linears.1.scale', 'linears.1.zero_point', 'linears.1._packed_params.dtype', 'linears.1._packed_params._packed_params', 'linears.2.scale', 'linears.2.zero_point', 'linears.2._packed_params.dtype', 'linears.2._packed_params._packed_params', 'linears.3.scale', 'linears.3.zero_point', 'linears.3._packed_params.dtype', 'linears.3._packed_params._packed_params', 'linears.4.scale', 'linears.4.zero_point', 'linears.4._packed_params.dtype', 'linears.4._packed_params._packed_params'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/.local/lib/python3.8/site-packages/torch/_utils.py:314: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tMissing key(s) in state_dict: \"linears.0.weight\", \"linears.0.bias\", \"linears.1.weight\", \"linears.1.bias\", \"linears.2.weight\", \"linears.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tUnexpected key(s) in state_dict: \"linears.0.scale\", \"linears.0.zero_point\", \"linears.0._packed_params.dtype\", \"linears.0._packed_params._packed_params\", \"linears.1.scale\", \"linears.1.zero_point\", \"linears.1._packed_params.dtype\", \"linears.1._packed_params._packed_params\", \"linears.2.scale\", \"linears.2.zero_point\", \"linears.2._packed_params.dtype\", \"linears.2._packed_params._packed_params\", \"linears.3.scale\", \"linears.3.zero_point\", \"linears.3._packed_params.dtype\", \"linears.3._packed_params._packed_params\", \"linears.4.scale\", \"linears.4.zero_point\", \"linears.4._packed_params.dtype\", \"linears.4._packed_params._packed_params\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(q_dict\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m      8\u001b[0m model_qd \u001b[39m=\u001b[39m MLP(param)\n\u001b[0;32m----> 9\u001b[0m model_qd\u001b[39m.\u001b[39;49mload_state_dict(q_dict)\n\u001b[1;32m     11\u001b[0m loss, acc \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mevaluate_model(model, test_loader, device)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP:\n\tMissing key(s) in state_dict: \"linears.0.weight\", \"linears.0.bias\", \"linears.1.weight\", \"linears.1.bias\", \"linears.2.weight\", \"linears.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tUnexpected key(s) in state_dict: \"linears.0.scale\", \"linears.0.zero_point\", \"linears.0._packed_params.dtype\", \"linears.0._packed_params._packed_params\", \"linears.1.scale\", \"linears.1.zero_point\", \"linears.1._packed_params.dtype\", \"linears.1._packed_params._packed_params\", \"linears.2.scale\", \"linears.2.zero_point\", \"linears.2._packed_params.dtype\", \"linears.2._packed_params._packed_params\", \"linears.3.scale\", \"linears.3.zero_point\", \"linears.3._packed_params.dtype\", \"linears.3._packed_params._packed_params\", \"linears.4.scale\", \"linears.4.zero_point\", \"linears.4._packed_params.dtype\", \"linears.4._packed_params._packed_params\". "
     ]
    }
   ],
   "source": [
    "# Loading pretrained model\n",
    "modeldict = torch.load('models/mlp.ckpt')\n",
    "model = MLP(param)\n",
    "model.load_state_dict(modeldict)\n",
    "\n",
    "q_dict = torch.load('models/mlp_dynamicq.ckpt')\n",
    "print(q_dict.keys())\n",
    "model_qd = MLP(param)\n",
    "model_qd.load_state_dict(q_dict)\n",
    "\n",
    "loss, acc = utils.evaluate_model(model, test_loader, device)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "\n",
    "# model.to(device)\n",
    "# quantized_model.eval()\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     correctq = 0\n",
    "#     totalq = 0\n",
    "#     total = 0\n",
    "#     correct = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images_cuda = images.to(device)\n",
    "#         labels_cuda = labels.to(device)\n",
    "\n",
    "#         outputsq = quantized_model(images)\n",
    "#         _, predictedq = torch.max(outputsq.data, 1)\n",
    "#         totalq += labels.size(0)\n",
    "#         correctq += (predictedq == labels).sum().item()\n",
    "        \n",
    "#         outputs = model(images_cuda)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels_cuda.size(0)\n",
    "#         correct += (predicted == labels_cuda).sum().item()\n",
    "        \n",
    "\n",
    "#     print('Accuracy of the quantized model on the test images: {} %'.format(100 * correctq / totalq))\n",
    "#     print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "utils.print_model_size(model)\n",
    "utils.print_model_size(model_qd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
