{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from fedlern.models.mlp import MLP\n",
    "from fedlern.models.resnet_v2 import ResNet18\n",
    "from fedlern.train_utils import *\n",
    "from fedlern.quant_utils import *\n",
    "import fedlern.utils as utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cuda_device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu:0\")\n",
    "\n",
    "#stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "stats = (0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = prepare_dataloader_cifar(num_workers=8, train_batch_size=batch_size, eval_batch_size=batch_size, stats=stats)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET no quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 92.49999237060547%\n",
      "44.77 MB\n",
      "FP32 CPU Inference Latency: 6.57 ms / sample\n",
      "FP32 CUDA Inference Latency: 4.21 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "model = ResNet18()\n",
    "load_model(model, './saved_models/resnet18_cifar10_92-5.pt', device)\n",
    "\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "\n",
    "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 92.24999237060547%\n",
      "44.77 MB\n",
      "FP32 CPU Inference Latency: 9.38 ms / sample\n",
      "FP32 CUDA Inference Latency: 3.97 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, './saved_models/resnet18_cifar10_92-2.pt', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 92.67999267578125%\n",
      "44.77 MB\n",
      "CPU Inference Latency: 9.94 ms / sample\n",
      "CUDA Inference Latency: 4.32 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, './saved_models/resnet18v2_cifar10.pt', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET Quantization 4 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 79.60999298095703%\n",
      "44.77 MB\n",
      "CPU Inference Latency: 9.94 ms / sample\n",
      "CUDA Inference Latency: 4.32 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, './saved_models/resnet_4bits_2023-06-17_19-33.pt', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0, Accuracy: 83.66000366210938%\n",
      "44.77 MB\n",
      "FP32 CPU Inference Latency: 9.94 ms / sample\n",
      "FP32 CUDA Inference Latency: 4.32 ms / sample\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = ResNet18()\n",
    "load_model(model, './saved_models/resnet_8bits_2023-06-17_16-05.pt', device)\n",
    "\n",
    "# Test the model\n",
    "loss, acc = evaluate_model(model, test_loader, device,)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "print_model_size(model)\n",
    "\n",
    "# Measure inference latency\n",
    "cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [ 28 * 28, # input\n",
    "                512, 256, 128, 64,\n",
    "                10 ] #output\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # normalize the image with mean=0.5 and std=0.5\n",
    "])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_dataset = datasets.MNIST(root='data/', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['linears.0.scale', 'linears.0.zero_point', 'linears.0._packed_params.dtype', 'linears.0._packed_params._packed_params', 'linears.1.scale', 'linears.1.zero_point', 'linears.1._packed_params.dtype', 'linears.1._packed_params._packed_params', 'linears.2.scale', 'linears.2.zero_point', 'linears.2._packed_params.dtype', 'linears.2._packed_params._packed_params', 'linears.3.scale', 'linears.3.zero_point', 'linears.3._packed_params.dtype', 'linears.3._packed_params._packed_params', 'linears.4.scale', 'linears.4.zero_point', 'linears.4._packed_params.dtype', 'linears.4._packed_params._packed_params'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/.local/lib/python3.8/site-packages/torch/_utils.py:314: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tMissing key(s) in state_dict: \"linears.0.weight\", \"linears.0.bias\", \"linears.1.weight\", \"linears.1.bias\", \"linears.2.weight\", \"linears.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tUnexpected key(s) in state_dict: \"linears.0.scale\", \"linears.0.zero_point\", \"linears.0._packed_params.dtype\", \"linears.0._packed_params._packed_params\", \"linears.1.scale\", \"linears.1.zero_point\", \"linears.1._packed_params.dtype\", \"linears.1._packed_params._packed_params\", \"linears.2.scale\", \"linears.2.zero_point\", \"linears.2._packed_params.dtype\", \"linears.2._packed_params._packed_params\", \"linears.3.scale\", \"linears.3.zero_point\", \"linears.3._packed_params.dtype\", \"linears.3._packed_params._packed_params\", \"linears.4.scale\", \"linears.4.zero_point\", \"linears.4._packed_params.dtype\", \"linears.4._packed_params._packed_params\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(q_dict\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m      8\u001b[0m model_qd \u001b[39m=\u001b[39m MLP(param)\n\u001b[0;32m----> 9\u001b[0m model_qd\u001b[39m.\u001b[39;49mload_state_dict(q_dict)\n\u001b[1;32m     11\u001b[0m loss, acc \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mevaluate_model(model, test_loader, device)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP:\n\tMissing key(s) in state_dict: \"linears.0.weight\", \"linears.0.bias\", \"linears.1.weight\", \"linears.1.bias\", \"linears.2.weight\", \"linears.2.bias\", \"linears.3.weight\", \"linears.3.bias\", \"linears.4.weight\", \"linears.4.bias\". \n\tUnexpected key(s) in state_dict: \"linears.0.scale\", \"linears.0.zero_point\", \"linears.0._packed_params.dtype\", \"linears.0._packed_params._packed_params\", \"linears.1.scale\", \"linears.1.zero_point\", \"linears.1._packed_params.dtype\", \"linears.1._packed_params._packed_params\", \"linears.2.scale\", \"linears.2.zero_point\", \"linears.2._packed_params.dtype\", \"linears.2._packed_params._packed_params\", \"linears.3.scale\", \"linears.3.zero_point\", \"linears.3._packed_params.dtype\", \"linears.3._packed_params._packed_params\", \"linears.4.scale\", \"linears.4.zero_point\", \"linears.4._packed_params.dtype\", \"linears.4._packed_params._packed_params\". "
     ]
    }
   ],
   "source": [
    "# Loading pretrained model\n",
    "modeldict = torch.load('saved_models/mlp.ckpt')\n",
    "model = MLP(param)\n",
    "model.load_state_dict(modeldict)\n",
    "\n",
    "q_dict = torch.load('saved_models/mlp_dynamicq.ckpt')\n",
    "print(q_dict.keys())\n",
    "model_qd = MLP(param)\n",
    "model_qd.load_state_dict(q_dict)\n",
    "\n",
    "loss, acc = utils.evaluate_model(model, test_loader, device)\n",
    "print(f'Loss: {loss}, Accuracy: {acc*100}%')\n",
    "\n",
    "# model.to(device)\n",
    "# quantized_model.eval()\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     correctq = 0\n",
    "#     totalq = 0\n",
    "#     total = 0\n",
    "#     correct = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images_cuda = images.to(device)\n",
    "#         labels_cuda = labels.to(device)\n",
    "\n",
    "#         outputsq = quantized_model(images)\n",
    "#         _, predictedq = torch.max(outputsq.data, 1)\n",
    "#         totalq += labels.size(0)\n",
    "#         correctq += (predictedq == labels).sum().item()\n",
    "        \n",
    "#         outputs = model(images_cuda)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels_cuda.size(0)\n",
    "#         correct += (predicted == labels_cuda).sum().item()\n",
    "        \n",
    "\n",
    "#     print('Accuracy of the quantized model on the test images: {} %'.format(100 * correctq / totalq))\n",
    "#     print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "utils.print_model_size(model)\n",
    "utils.print_model_size(model_qd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
